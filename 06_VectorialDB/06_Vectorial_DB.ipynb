{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Taller 06: Base de Datos Vectoriales"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parte 1: Recuperación con TF-IDF\n",
    "\n",
    "**1. Carga los datos en Python**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Carga el archivo CSV en un DataFrame\n",
    "df = pd.read_csv(\"../data/wiki_movie_plots_deduped.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filtra únicamente las columnas Title y Plot\n",
    "df_filtered = df[['Title', 'Plot']]\n",
    "\n",
    "# Muestra las primeras filas del DataFrame filtrado\n",
    "print(df_filtered.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                              Title  \\\n",
      "0            Kansas Saloon Smashers   \n",
      "1     Love by the Light of the Moon   \n",
      "2           The Martyred Presidents   \n",
      "3  Terrible Teddy, the Grizzly King   \n",
      "4            Jack and the Beanstalk   \n",
      "\n",
      "                                                Plot  \n",
      "0  A bartender is working at a saloon, serving dr...  \n",
      "1  The moon, painted with a smiling face hangs ov...  \n",
      "2  The film, just over a minute long, is composed...  \n",
      "3  Lasting just 61 seconds and consisting of two ...  \n",
      "4  The earliest known adaptation of the classic f...  \n"
     ]
    }
   ],
   "source": [
    "# Filtra únicamente las columnas Title y Plot\n",
    "df_filtered = df[['Title', 'Plot']]\n",
    "\n",
    "# Muestra las primeras filas del DataFrame filtrado\n",
    "print(df_filtered.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2. Configurar TF-IDF**\n",
    "\n",
    "- usa la libreria scikit-lear para calcular los puntajes TF-IDF de los plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                  aaron  abandon  abandoned  abandons  abby  \\\n",
      "Title                                                                         \n",
      "Kansas Saloon Smashers              0.0      0.0        0.0       0.0   0.0   \n",
      "Love by the Light of the Moon       0.0      0.0        0.0       0.0   0.0   \n",
      "The Martyred Presidents             0.0      0.0        0.0       0.0   0.0   \n",
      "Terrible Teddy, the Grizzly King    0.0      0.0        0.0       0.0   0.0   \n",
      "Jack and the Beanstalk              0.0      0.0        0.0       0.0   0.0   \n",
      "\n",
      "                                  abducted  abhi  abilities  ability  \\\n",
      "Title                                                                  \n",
      "Kansas Saloon Smashers                 0.0   0.0        0.0      0.0   \n",
      "Love by the Light of the Moon          0.0   0.0        0.0      0.0   \n",
      "The Martyred Presidents                0.0   0.0        0.0      0.0   \n",
      "Terrible Teddy, the Grizzly King       0.0   0.0        0.0      0.0   \n",
      "Jack and the Beanstalk                 0.0   0.0        0.0      0.0   \n",
      "\n",
      "                                      able  ...   yu  zack  zamindar  zero  \\\n",
      "Title                                       ...                              \n",
      "Kansas Saloon Smashers            0.000000  ...  0.0   0.0       0.0   0.0   \n",
      "Love by the Light of the Moon     0.000000  ...  0.0   0.0       0.0   0.0   \n",
      "The Martyred Presidents           0.000000  ...  0.0   0.0       0.0   0.0   \n",
      "Terrible Teddy, the Grizzly King  0.000000  ...  0.0   0.0       0.0   0.0   \n",
      "Jack and the Beanstalk            0.062146  ...  0.0   0.0       0.0   0.0   \n",
      "\n",
      "                                  zhang  zoe  zombie  zombies  zone  zoo  \n",
      "Title                                                                     \n",
      "Kansas Saloon Smashers              0.0  0.0     0.0      0.0   0.0  0.0  \n",
      "Love by the Light of the Moon       0.0  0.0     0.0      0.0   0.0  0.0  \n",
      "The Martyred Presidents             0.0  0.0     0.0      0.0   0.0  0.0  \n",
      "Terrible Teddy, the Grizzly King    0.0  0.0     0.0      0.0   0.0  0.0  \n",
      "Jack and the Beanstalk              0.0  0.0     0.0      0.0   0.0  0.0  \n",
      "\n",
      "[5 rows x 5000 columns]\n"
     ]
    }
   ],
   "source": [
    "import unicodedata\n",
    "import re\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# Función para limpiar texto\n",
    "def clean_text(text):\n",
    "    # Convertir a minúsculas\n",
    "    text = text.lower()\n",
    "    # Eliminar tildes\n",
    "    text = ''.join(\n",
    "        c for c in unicodedata.normalize('NFD', text) if unicodedata.category(c) != 'Mn'\n",
    "    )\n",
    "    # Eliminar números, puntuaciones y caracteres no alfabéticos\n",
    "    text = re.sub(r'[^a-z\\s]', '', text)\n",
    "    return text\n",
    "\n",
    "# Inicializa el vectorizador TF-IDF con el preprocesador personalizado\n",
    "tfidf_vectorizer = TfidfVectorizer(\n",
    "    max_features=5000,  # Limita el vocabulario\n",
    "    preprocessor=clean_text,  # Aplica la limpieza personalizada\n",
    "    token_pattern=r'\\b[a-z]{2,}\\b'  # Solo considera palabras de al menos 2 letras\n",
    ")\n",
    "\n",
    "# Calcula los puntajes TF-IDF para los Plots\n",
    "tfidf_matrix = tfidf_vectorizer.fit_transform(df_filtered['Plot'].fillna(''))\n",
    "\n",
    "# Convierte la matriz dispersa en un DataFrame\n",
    "tfidf_df = pd.DataFrame(\n",
    "    tfidf_matrix.toarray(),\n",
    "    columns=tfidf_vectorizer.get_feature_names_out(),\n",
    "    index=df_filtered['Title']\n",
    ")\n",
    "\n",
    "# Muestra las primeras filas del DataFrame TF-IDF\n",
    "print(tfidf_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3. Realizar Consultas:**\n",
    "\n",
    "- Escribe una función que calculo la similitud entre una consulta y los documentos usando la matriz TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                 Title  Similarity\n",
      "18255                 The Medicine Man    0.452338\n",
      "18965                Death Is a Number    0.440332\n",
      "20811       My Wrongs #8245–8249 & 117    0.392925\n",
      "22406                        King Dave    0.335430\n",
      "18390            The Man in the Mirror    0.331631\n",
      "1942                  Murder in Harlem    0.330803\n",
      "15734                         The Road    0.324203\n",
      "16472  Cheech & Chong's Animated Movie    0.316461\n",
      "23866              Everyday I Love You    0.314217\n",
      "27894                    Junior Senior    0.307387\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "def calcular_similitud(query, tfidf_vectorizer, tfidf_matrix, titles):\n",
    "    # Limpia la consulta usando la misma lógica de preprocesamiento\n",
    "    query_cleaned = clean_text(query)\n",
    "\n",
    "    # Vectoriza la consulta\n",
    "    query_tfidf = tfidf_vectorizer.transform([query_cleaned])\n",
    "\n",
    "    # Calcula la similitud coseno entre la consulta y los documentos\n",
    "    similitudes = cosine_similarity(query_tfidf, tfidf_matrix).flatten()\n",
    "\n",
    "    # Crea un DataFrame con los resultados\n",
    "    resultados = pd.DataFrame({\n",
    "        'Title': titles,\n",
    "        'Similarity': similitudes\n",
    "    })\n",
    "\n",
    "    # Ordena los documentos por similitud en orden descendente\n",
    "    resultados_ordenados = resultados.sort_values(by='Similarity', ascending=False)\n",
    "\n",
    "    return resultados_ordenados\n",
    "\n",
    "# Ejemplo de uso\n",
    "consulta = \"man\"\n",
    "resultados = calcular_similitud(consulta, tfidf_vectorizer, tfidf_matrix, df_filtered['Title'])\n",
    "\n",
    "# Muestra los resultados\n",
    "print(resultados.head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**4. Evaluar los resultados:**\n",
    "\n",
    "- Registra los documentos recuperados y analiza su relevancia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resultados guardados en: data\\resultados_recuperados.csv\n",
      "Documentos relevantes (similitud >= 0.4): 2\n",
      "Documentos relevantes:\n",
      "                   Title  Similarity\n",
      "18255   The Medicine Man    0.452338\n",
      "18965  Death Is a Number    0.440332\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "def registrar_documentos(resultados, output_path=\"resultados_recuperados.csv\", threshold=0.5):\n",
    "    # Asegúrate de que el directorio existe\n",
    "    os.makedirs(os.path.dirname(output_path), exist_ok=True)\n",
    "    \n",
    "    # Marca los documentos como relevantes o no según el umbral\n",
    "    resultados['Relevancia'] = resultados['Similarity'] >= threshold\n",
    "\n",
    "    # Guarda los resultados en un archivo CSV\n",
    "    resultados.to_csv(output_path, index=False)\n",
    "    print(f\"Resultados guardados en: {output_path}\")\n",
    "\n",
    "    # Filtra los documentos relevantes\n",
    "    resultados_filtrados = resultados[resultados['Relevancia']]\n",
    "    print(f\"Documentos relevantes (similitud >= {threshold}): {len(resultados_filtrados)}\")\n",
    "\n",
    "    return resultados_filtrados\n",
    "\n",
    "# Llama a la función con los resultados de la consulta\n",
    "ruta_salida = os.path.join(\"data\", \"resultados_recuperados.csv\")\n",
    "documentos_relevantes = registrar_documentos(resultados, output_path=ruta_salida, threshold=0.4)\n",
    "\n",
    "# Analiza los resultados relevantes\n",
    "print(\"Documentos relevantes:\")\n",
    "print(documentos_relevantes[['Title', 'Similarity']].head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parte 2: Recuperación con BM25\n",
    "\n",
    "**1. Configurar Elasticsearch:**\n",
    "\n",
    "- Reutiliza el índice creado en el Ejercicio 1 para realizar consultas basadas en BM25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: elasticsearch in c:\\users\\diego\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (8.17.0)Note: you may need to restart the kernel to use updated packages.\n",
      "\n",
      "Requirement already satisfied: elastic-transport<9,>=8.15.1 in c:\\users\\diego\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from elasticsearch) (8.17.0)\n",
      "Requirement already satisfied: urllib3<3,>=1.26.2 in c:\\users\\diego\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from elastic-transport<9,>=8.15.1->elasticsearch) (2.2.3)\n",
      "Requirement already satisfied: certifi in c:\\users\\diego\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from elastic-transport<9,>=8.15.1->elasticsearch) (2024.12.14)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.3.1 -> 24.3.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "pip install elasticsearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from elasticsearch import Elasticsearch\n",
    "from elasticsearch.helpers import bulk\n",
    "import pandas as pd\n",
    "\n",
    "# Conectar a Elasticsearch\n",
    "es = Elasticsearch([{'host': 'localhost', 'port': 9200}])\n",
    "\n",
    "# Cargar datos del archivo CSV\n",
    "df = pd.read_csv(\"../data/wiki_movie_plots_deduped.csv\")\n",
    "df_filtered = df[['Title', 'Plot']]\n",
    "\n",
    "# Crear un índice en Elasticsearch\n",
    "index_name = \"movies_bm25\"\n",
    "if es.indices.exists(index=index_name):\n",
    "    es.indices.delete(index=index_name)\n",
    "\n",
    "es.indices.create(index=index_name, body={\n",
    "    \"settings\": {\n",
    "        \"number_of_shards\": 1,\n",
    "        \"number_of_replicas\": 0\n",
    "    },\n",
    "    \"mappings\": {\n",
    "        \"properties\": {\n",
    "            \"Title\": {\"type\": \"text\"},\n",
    "            \"Plot\": {\"type\": \"text\"}\n",
    "        }\n",
    "    }\n",
    "})\n",
    "\n",
    "# Insertar los documentos en el índice\n",
    "def generate_data(df):\n",
    "    for _, row in df.iterrows():\n",
    "        yield {\n",
    "            \"_index\": index_name,\n",
    "            \"_source\": {\n",
    "                \"Title\": row['Title'],\n",
    "                \"Plot\": row['Plot']\n",
    "            }\n",
    "        }\n",
    "\n",
    "bulk(es, generate_data(df_filtered))\n",
    "print(f\"Índice '{index_name}' creado y documentos insertados.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2. Realizar consultas usando BM25**\n",
    "\n",
    "- Configura y ejecuta consultas: Realiza consultas a Elasticsearch con las palabras clave, como \"dinosaurs\" o \"cyborg\".\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Función para realizar consultas\n",
    "def search_query(query, index_name):\n",
    "    response = es.search(\n",
    "        index=index_name,\n",
    "        body={\n",
    "            \"query\": {\n",
    "                \"match\": {\n",
    "                    \"Plot\": query\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "    )\n",
    "    return response\n",
    "\n",
    "# Consultas de ejemplo\n",
    "keywords = [\"dinosaurs\", \"cyborg\"]\n",
    "for keyword in keywords:\n",
    "    results = search_query(keyword, index_name)\n",
    "    print(f\"Resultados para la consulta '{keyword}':\")\n",
    "    for hit in results['hits']['hits']:\n",
    "        print(f\"Title: {hit['_source']['Title']}, Score: {hit['_score']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3. Evaluar los resultados**\n",
    "\n",
    "- Compara con los resultados de TF-IDF:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Recuperar títulos y similitudes para BM25\n",
    "def get_bm25_results(query, index_name):\n",
    "    results = search_query(query, index_name)\n",
    "    return pd.DataFrame([\n",
    "        {\"Title\": hit[\"_source\"][\"Title\"], \"BM25_Score\": hit[\"_score\"]}\n",
    "        for hit in results[\"hits\"][\"hits\"]\n",
    "    ])\n",
    "\n",
    "# Comparar TF-IDF y BM25\n",
    "consulta = \"dinosaurs\"\n",
    "bm25_results = get_bm25_results(consulta, index_name)\n",
    "tfidf_results = calcular_similitud(consulta, tfidf_vectorizer, tfidf_matrix, df_filtered['Title'])\n",
    "\n",
    "# Merge y comparación\n",
    "comparison = pd.merge(\n",
    "    bm25_results, \n",
    "    tfidf_results.rename(columns={\"Similarity\": \"TF-IDF_Score\"}), \n",
    "    on=\"Title\", \n",
    "    how=\"outer\"\n",
    ").fillna(0)\n",
    "\n",
    "# Exportar a CSV para análisis\n",
    "comparison.to_csv(\"comparison_results.csv\", index=False)\n",
    "print(\"Comparación exportada a 'comparison_results.csv'.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
